---
title: "Introduction to multiple linear regression"
author: "Dr. Olanrewaju Akande"
date: "Aug 29, 2019"
output:
  xaringan::moon_reader:
    css: "slides.css"
    logo: img/class_logo.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(magick)
library(knitr)
library(kableExtra)
```

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 2.65, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
# For nonsese...
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, 0.5, 1)) 
})
opts_chunk$set(fig.path='figure/beamer-',fig.align='center',fig.show='hold',size='footnotesize', small.mar=TRUE)
```


## Outline

- Motivating Example

- Multiple linear regression

- Interpretation of coefficients

- Hypothesis tests for coefficients

- Confidence interval for coefficients

- Predictions

- Case study


---
## Introduction

- In the stats module of the MIDS summer online review, you were introduced to simple linear regression.

- Today, we will begin our series of lectures on multiple linear regression. 

- For now, we will restrict our attention to model interpretation, testing, and predictions under multiple linear regression. 

- In the next class, we will start to explore model specification, assessment and validation. 


---

class: center, middle

# Motivating Example


---

## Sex discrimination
- In 1970â€™s, Harris Trust and Savings Bank was sued for discrimination on the basis of sex.  

- Analysis of salaries of employees of one type (skilled, entry level clerical) presented as evidence
by the defense.

- The data is in the file *wagediscrim.txt* on Sakai.

- Did female employees tend to receive lower starting salaries than similarly qualified and experienced male employees?


---
## The Data

93 employees on data file (61 female, 32 male).

Variable    | Description
:------------- | :------------ 
bsal | Annual salary at time of hire
sal77 | Annual salary in 1977.
educ | years of education.
exper | months previous work prior to hire at bank.
fsex | 1 if female, 0 if male
senior | months worked at bank since hired
age | months


---
## The Data

Let's get a sense of the data: how many rows, how many columns?
```{r}
wages = read.csv("data/wagediscrim.txt", header= T)
dim(wages)
```

Let's take a look at the first few rows of the data
```{r}
head(wages)
```


---
## Exploratory Data Analysis (EDA)

How about quick summaries of each variable to know the range of data we are working with
```{r}
wages$fsex <- factor(wages$fsex)
summary(wages)
```


---
## EDA

Since we only care about comparing starting salaries for male and female employees, let's look at a boxplot of `bsal` by `sex`.
```{r fig.height=3}
boxplot(bsal~sex,data=wages,ylab="Sex",horizontal=TRUE,
        xlab="Base Salary")
```

--
<div class="question">
What do you think? What can you infer from this plot?
</div>


---
## T.test?

We could go further and try a t-test for the hypotheses:
.small[
$$H_0: \mu_{male} - \mu_{female} \leq 0 \ \ \textrm{vs.} \ \ H_A: \mu_{male} - \mu_{female} > 0$$
]
```{r}
t.test(bsal~fsex,data=wages,alternative="greater")
```

--
<div class="question">
Is a t.test sufficient here? Any concerns?
</div>


---
## EDA

- T-test shows men started at higher salaries than women (t=5.83, p $<$ .0001).

- But, it **doesn't** control for other characteristics.

- There are other variables that are correlated with `bsal`. Here's the correlation matrix of all numerical variables using the *corr* function in R.
```{r echo=FALSE}
kable(round(cor(wages[,!is.element(colnames(wages),c("sex","fsex"))]),2)) %>%
  kable_styling(font_size = 20)
```


---
## EDA

In fact, let's take a look at scatter plots of all variables
```{r fig.height=4.5}
pairs(wages)
```


---
## EDA

Too busy! Let's take a closer look at some variables.

First, `bsal` vs. `senior`
```{r fig.height=3}
plot(wages$bsal~wages$senior,xlab="Seniority",ylab="Base Salary")
abline(lm(bsal~senior,data=wages))
```


---
## EDA

Next, `bsal` vs. `age`
```{r fig.height=3.6}
plot(wages$bsal~wages$age,xlab="Age",ylab="Base Salary")
abline(lm(bsal~age,data=wages))
```


---
## EDA

`bsal` vs. `educ`
```{r fig.height=3.6}
plot(wages$bsal~wages$educ,xlab="Education",ylab="Base Salary")
abline(lm(bsal~educ,data=wages))
```


---
## EDA

Finally, `bsal` vs. `exper`
```{r fig.height=3}
plot(wages$bsal~wages$exper,xlab="Experience",ylab="Base Salary")
abline(lm(bsal~exper,data=wages))
```
Clearly, they are other variables that may be relevant in explaining baseline salary.

---

class: center, middle

# Multiple Linear Regression





